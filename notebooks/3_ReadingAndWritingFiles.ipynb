{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and writing files, JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents:\n",
    "\n",
    "* File Input/Output\n",
    "* Reading and writing JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Input/Output\n",
    "\n",
    "A huge portion of our input data will come from files that we have stored on our computer (on the file system). A lot of analysis of these files is done in memory in Python, when working with them. We have to save them back to the file system to store the results. So, mastering the art of reading and writing is crucial in programming.\n",
    "\n",
    "Until now, we have run stuff (almost instantly) in our Jupyter Notebooks, but imagine that we write code that takes a couple of ours to run on a large collection of files. Then we want to save the result, either for further analysis, or to make these files available (i.e. sharing) in your research. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code opens a file in our filesystem, prints the first 10 lines and closes the file. Please note that this file must exist on your computer. If you only have downloaded this notebook, go back to the repository, download the file, and place it in the appropriate path (or change the path below). This path corresponds to the folder structure on your file system. \n",
    "\n",
    "> **Please note:** The code below shows you how the `open()` function works. It's better to use a `width` block (see below), which does this opening and closing for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open('data/adams-hhgttg.txt', 'r', encoding='utf-8')\n",
    "\n",
    "for i, banana in enumerate(infile):\n",
    "    if i == 10:\n",
    "        break\n",
    "    print(banana)\n",
    "\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key passage here is the one in which the `open()` function opens a file and return a **file object** (hint: try printing the type of `infile`), and it is commonly used with the following three parameters: the **name of the file** that we want to open, the **mode** and the **encoding**. \n",
    "\n",
    "- **filename**: the name of the file to open, this corresponds to the full/relative path to the file from the notebook. \n",
    "\n",
    "- the **mode** in which we want to open a file: the most commonly used values are `r` for **reading** (default, which means that you don't have to put this in explicitly), `w` for **writing** (overwriting existing files), and `a` for **appending**. (Note that [the documentation](https://docs.python.org/3/library/functions.html#open) report mode values that may be necessary in some exceptional case)\n",
    "\n",
    "- **encoding**: which mapping of string to code points (conversion to bytes) to use, more on this later. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**IMPORTANT**: every opened file should be **closed** by using the function `close()` before the end of the program, or the file could be unavailable to successive manipulations or for other programs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other ways to read a text file, among which the use of the methods `read()` and `readlines()`, that would simplify the above function in:\n",
    "\n",
    "```python\n",
    "infile = open('data/adams-hhgttg.txt', 'r', encoding='utf-8')\n",
    "text = infile.readlines()\n",
    "print(text[:10])\n",
    "infile.close()\n",
    "```\n",
    "\n",
    "However, these methods **read the whole file at once**, thus creating capacity/efficiency problems when working with big corpora.\n",
    "\n",
    "In the solution we adopt here the input file is read line by line, so that at any given moment **only one line of text** is loaded into memory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see all file object methods, including examples, on this W3schools page: https://www.w3schools.com/python/python_ref_file.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/adams-hhgttg.txt', encoding='utf-8') as infile:  # The file is opened\n",
    "    \n",
    "    lines = infile.readlines()\n",
    "    \n",
    "# As soon as we exit the indented scope, the file is closed again \n",
    "# (and made available to other programs on your computer)\n",
    "print(lines[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/', encoding='utf-8') as infile:  # The file is opened\n",
    "    \n",
    "    lines = infile.readlines()\n",
    "    \n",
    "# As soon as we exit the indented scope, the file is closed again \n",
    "# (and made available to other programs on your computer)\n",
    "print(lines[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The with statement \n",
    "\n",
    "A `with` statement is used to wrap the execution of a block of code.\n",
    "\n",
    "Using this construction to open files has three major advantages:\n",
    "\n",
    "- there is no need to explicitly  close the file (the file is automatically closed as soon as the nested code exits)\n",
    "- the file is closed automatically even when unhandled errors cause the program to crash\n",
    "- the code is way clearer (it is trivial to identify where in the code a file is opened) \n",
    "\n",
    "Thus, you can  make it yourself a bit easier. Forget about the explicit `.close()` method. The code above can be rewritten as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/adams-hhgttg.txt', encoding='utf-8') as infile:  # The file is opened\n",
    "    \n",
    "    lines = infile.readlines()\n",
    "    \n",
    "# As soon as we exit the indented scope, the file is closed again \n",
    "# (and made available to other programs on your computer)\n",
    "print(lines[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the indented with block is executed while the file is opened. It is automatically closed as the block is closed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz\n",
    "\n",
    "Hint: you can call `.read()` on the file object.\n",
    "\n",
    "* Write one function that takes a file path as argument and prints statistics about the file, giving:\n",
    "    * The number of words (often called 'tokens')\n",
    "    * The number of unique words (often called 'types')\n",
    "    * The type:token ratio (i.e. unique words / words)\n",
    "    * The 10 most frequent words, including their frequencies\n",
    "* Write a normalization or cleaning function that takes a string as argument, that pre-processes this text and returns a normalized version, by removing/substituting:\n",
    "    * Uppercase characters\n",
    "    * Punctuation\n",
    "* Call the normalization function inside the first function\n",
    "\n",
    "Test the function on the filepath in `file_path` below. Compare the results from running the function with and without normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "def get_file_statistics(file_path, normalization=False):\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as infile:\n",
    "        text = infile.read()\n",
    "        \n",
    "    if normalization:\n",
    "        text = normalize(text)\n",
    "        \n",
    "    words = text.split()\n",
    "       \n",
    "    n_words = len(words)\n",
    "    n_unique = len(set(words))\n",
    "        \n",
    "    print(\"Number of words:\", n_words)\n",
    "    print(\"Number of unique words:\", n_unique)\n",
    "    print(\"TTR:\", n_unique / n_words)\n",
    "    \n",
    "    counter = Counter(words)\n",
    "    most_common_words = counter.most_common(10)\n",
    "    \n",
    "    print(\"Frequencies:\")\n",
    "    for word, frequency in most_common_words:\n",
    "        print(\"\\t\", word, \"(\" + str(frequency) + \")\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "def get_file_statistics(file_path, normalization=False):\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as infile:\n",
    "        text = infile.read()\n",
    "        \n",
    "    if normalization:\n",
    "        text = normalize(text)\n",
    "        \n",
    "    words = text.split()\n",
    "       \n",
    "    n_words = len(words)\n",
    "    n_unique = len(set(words))\n",
    "        \n",
    "    print(\"Number of words:\", n_words)\n",
    "    print(\"Number of unique words:\", n_unique)\n",
    "    print(\"TTR:\", n_unique / n_words)\n",
    "    \n",
    "    counter = Counter(words)\n",
    "    most_common_words = counter.most_common(10)\n",
    "    \n",
    "    print(\"Frequencies:\")\n",
    "    for word, frequency in most_common_words:\n",
    "        print(\"\\t\", word, \"(\" + str(frequency) + \")\")\n",
    "\n",
    "\n",
    "def normalize(text):\n",
    "    \n",
    "    normalized_text = text.lower()\n",
    "    \n",
    "    for char in string.punctuation:\n",
    "        normalized_text = normalized_text.replace(char, '')\n",
    "    \n",
    "    return normalized_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/adams-hhgttg.txt'\n",
    "\n",
    "# your_function_name(file_path)\n",
    "get_file_statistics(file_path, normalization=False)\n",
    "\n",
    "print()\n",
    "\n",
    "get_file_statistics(file_path, normalization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing an output file in Python has a structure that is close to that we're used in our reading examples above. The main difference are:\n",
    "\n",
    "- the specification of the **mode** `w`\n",
    "- the use of the function `write()` for each line of text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Warning!** Opening an _existing_ file in `w` mode will erase its contents!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The folder you with to write the file to ('stuff' below) has to exist on the file system\n",
    "\n",
    "with open('stuff/output-test-1.txt', 'w', encoding='utf-8') as outfile:\n",
    "    \n",
    "    outfile.write(\"My name is:\")\n",
    "    outfile.write(\"John\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When writing line by line, it's up to you to take care of the **newlines** by appending `\\n` to each line. Unlike the `print()` function, the `write()` function has no standard line-end character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stuff/output-test-2.txt', 'w', encoding='utf-8') as outfile:\n",
    "    \n",
    "    outfile.write(\"My name is:\\n\")\n",
    "    outfile.write(\"Alexander\")\n",
    "    \n",
    "    \n",
    "    outfile.write(\"ééèèüAæøå\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect the file we just created with the command line. The following is not Python, but a basic command line tool to print the contents of a file. At least on Mac and Linux, this works. Otherwise, just navigate to the file in your file explorer and open it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Prepending a `!` to a command executes a program on your computer. Use it with care and don't run such a cell in a notebook that you do not trust!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat stuff/output-test-2.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz\n",
    "\n",
    "Instead of printing the statistics in the previous quiz, write them to a file. For instance, use the file path in `file_path` to write the file to. Copy your function from above, rename it and add the required code to it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "file_path = 'stuff/adams-hhgttg-statistics.txt'\n",
    "\n",
    "# your_adapted_function_that_writes_statistics(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "def get_file_statistics(file_path, target_file, normalization=False):\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as infile:\n",
    "        text = infile.read()\n",
    "        \n",
    "    if normalization:\n",
    "        text = normalize(text)\n",
    "        \n",
    "    words = text.split()\n",
    "       \n",
    "    n_words = len(words)\n",
    "    n_unique = len(set(words))\n",
    "        \n",
    "    \n",
    "    \n",
    "    counter = Counter(words)\n",
    "    most_common_words = counter.most_common(10)\n",
    "    \n",
    "\n",
    "        \n",
    "    with open(target_file, 'w', encoding='utf-8') as outfile:\n",
    "        \n",
    "        outfile.write(\"Number of words:\" + str(n_words))\n",
    "        outfile.write('\\n')\n",
    "        \n",
    "        outfile.write(\"Number of unique words:\" + str(n_unique))\n",
    "        outfile.write('\\n')\n",
    "        \n",
    "        outfile.write(\"TTR:\" + str(n_unique / n_words))\n",
    "        outfile.write('\\n')\n",
    "\n",
    "        outfile.write(\"Frequencies:\")\n",
    "        for word, frequency in most_common_words:\n",
    "            outfile.write(\"\\t\" + word + \"(\" + str(frequency) + \")\")\n",
    "            outfile.write('\\n')\n",
    "\n",
    "def normalize(text):\n",
    "    \n",
    "    normalized_text = text.lower()\n",
    "    \n",
    "    for char in string.punctuation:\n",
    "        normalized_text = normalized_text.replace(char, '')\n",
    "    \n",
    "    return normalized_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_file_statistics('data/adams-hhgttg.txt', target_file=file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly check its contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat stuff/adams-hhgttg-statistics.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading files from a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function that reads through the folders and files in a directory. \n",
    "# Read through the data directory and all its contents.\n",
    "\n",
    "def read_through_folder(path):\n",
    "    \"\"\"\n",
    "    Read from all files in a given folder. \n",
    "    \n",
    "    Args:\n",
    "        path (str): Path to a folder\n",
    "        \n",
    "    Returns:\n",
    "        dict: dictionary with filenames as keys and their contents as value\n",
    "    \"\"\"\n",
    "    \n",
    "    files = os.listdir(path)\n",
    "    \n",
    "    data = dict()\n",
    "    \n",
    "    for n, file in enumerate(files, 1):\n",
    "        \n",
    "        filepath = os.path.join(path, file)\n",
    "        \n",
    "        content = read_from_file(filepath)\n",
    "        \n",
    "        print(n, file)\n",
    "        \n",
    "        data[file] = content[:100]\n",
    "        \n",
    "    return data\n",
    "    \n",
    "\n",
    "def read_from_file(filepath):\n",
    "    \n",
    "    with open(filepath, 'r', encoding='utf-8') as infile:\n",
    "        text = infile.read()\n",
    "        \n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/gutenberg-extension'\n",
    "\n",
    "data = read_through_folder(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function that reads through the folders and files in a directory. \n",
    "# Read through the data directory and all its contents.\n",
    "\n",
    "def read_through_folder(path):\n",
    "    \"\"\"\n",
    "    Read from all files in a given folder. \n",
    "    \n",
    "    Args:\n",
    "        path (str): Path to a folder\n",
    "        \n",
    "    Returns:\n",
    "        dict: dictionary with filenames as keys and their contents as value\n",
    "    \"\"\"\n",
    "    \n",
    "    data = dict()\n",
    "    \n",
    "    for root, dirs, files in os.walk(path):\n",
    "        \n",
    "#         print(dirs)\n",
    "#         print()\n",
    "        \n",
    "        # Read from the folders here\n",
    "        for folder in dirs:\n",
    "            \n",
    "            folderpath = os.path.join(root, folder)\n",
    "            files = os.listdir(folderpath)\n",
    "            \n",
    "#             print(files)\n",
    "#             print()\n",
    "            \n",
    "            data[folder] = dict()\n",
    "    \n",
    "            # Then every file in that folder\n",
    "            for n, file in enumerate(files, 1):\n",
    "\n",
    "                filepath = os.path.join(folderpath, file)\n",
    "                \n",
    "                if os.path.isdir(filepath):  # Some files can be folders\n",
    "                    continue\n",
    "\n",
    "                # Read its contents\n",
    "                content = read_from_file(filepath)\n",
    "\n",
    "#                 print(n, file)\n",
    "\n",
    "                print(type(data))\n",
    "                print(data)\n",
    "\n",
    "                data[folder][file] = content[:10]\n",
    "        \n",
    "                break\n",
    "        \n",
    "    return data\n",
    "    \n",
    "\n",
    "def read_from_file(filepath):\n",
    "    \"\"\"Give back the text from a file\"\"\"\n",
    "    \n",
    "    with open(filepath, 'r', encoding='utf-8') as infile:\n",
    "        text = infile.read()\n",
    "        \n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data'\n",
    "\n",
    "data = read_through_folder(path)\n",
    "\n",
    "for folder, value in data.items():\n",
    "    \n",
    "    for file, content in value.items():\n",
    "        print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looping through folders and files\n",
    "\n",
    "If you want to load in multiple files in a folder, without explicitly providing the file pointers/paths for each file, you can also point to a folder. We can use the built-in `os` module to loop through a folder and load multiple files in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # You only have to do this once in your code. \n",
    "           # Always put this at the top of your file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(os.walk(\"data/gutenberg-extension\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gutenberg_books = dict()  # Create an empty dictionary to store our data in\n",
    "\n",
    "for root, dirs, files in os.walk(\"data/gutenberg-extension\"):\n",
    "    for file in files:\n",
    "        \n",
    "        if not file.endswith('.txt'):  # Why this?\n",
    "            continue\n",
    "        \n",
    "        # You have to specify the full (relative) path, not only the file name.\n",
    "        file_path = os.path.join(root, file)  \n",
    "        \n",
    "        with open(file_path, encoding='utf-8') as infile:\n",
    "            gutenberg_books[file] = infile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gutenberg_books.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `os.walk()` method is convenient if you are dealing with a combination of files and folders, no matter how deep the hierarchy goes (folders in folders etc.). A simpler function is `os.listdir()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('data/gutenberg-extension/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gutenberg_books = dict()  # Create an empty dictionary to store our data in\n",
    "\n",
    "folder_path = \"data/gutenberg-extension\"\n",
    "\n",
    "for file in os.listdir(folder_path):\n",
    "\n",
    "    if not file.endswith('.txt'):  # Why this?\n",
    "        continue\n",
    "    \n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    \n",
    "    with open(file_path, encoding='utf-8') as infile:\n",
    "        gutenberg_books[file] = infile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gutenberg_books.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dictionary object now contains a lot of information: all the contents of all files. There's a chance that your browser/notebook will crash when calling the dictionary here. Instead, let's call a part of one of the books, the first 300 characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gutenberg_books['doyle-sherlock.txt'][:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and writing data in JSON and CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now know how we can read and write textual content to files on our file system. Two more structed and common data formats to store data in are JSON and CSV. If you are not familiar with these, take a look at:\n",
    "\n",
    "* JSON (https://www.w3schools.com/whatis/whatis_json.asp)\n",
    "* CSV (https://www.howtogeek.com/348960/what-is-a-csv-file-and-how-do-i-open-it/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntax of JSON is very similar to the syntax of `int`, `str`, `list` and `dict` data types in Python. \n",
    "\n",
    "The following data (excerpt) is taken from the data that feeds the Instagram page of the UvA (https://www.instagram.com/uva_amsterdam/). The API/service of Instagram returns web data in JSON that is used by your browser to show you a page with content. You can also find this when inspecting the source of the page. \n",
    "\n",
    "A JSON file (named `example.json`) that looks like this:\n",
    "```json\n",
    "{\n",
    "    \"biography\": \"Welcome to the UvA \\u274c\\u274c\\u274c \\nFind out more about our:\\n\\ud83c\\udfdb campuses \\ud83c\\udf93 education \\ud83d\\udd0e research\\nShare your \\ud83d\\udcf8 using: #uva_amsterdam\\nQuestions? Contact us:\",\n",
    "    \"blocked_by_viewer\": false,\n",
    "    \"restricted_by_viewer\": null,\n",
    "    \"country_block\": false,\n",
    "    \"external_url\": \"https://linkin.bio/uva_amsterdam\",\n",
    "    \"external_url_linkshimmed\": \"https://l.instagram.com/?u=https%3A%2F%2Flinkin.bio%2Fuva_amsterdam\\u0026e=ATOBo7L11uPBpsMfd6-pFnoBRaF3T-6ovlD9Blc2q1LGUjnmyuGutPfuK-ib70Bt_YmGu6cDNCX1Y1lC\\u0026s=1\",\n",
    "    \"edge_followed_by\": {\n",
    "        \"count\": 42241\n",
    "    },\n",
    "    \"fbid\": \"17841401222133463\",\n",
    "    \"followed_by_viewer\": false,\n",
    "    \"edge_follow\": {\n",
    "        \"count\": 362\n",
    "    },\n",
    "    \"follows_viewer\": false,\n",
    "    \"full_name\": \"UvA: University of Amsterdam\",\n",
    "    \"id\": \"1501672737\",\n",
    "    \"is_business_account\": true,\n",
    "    \"is_joined_recently\": false,\n",
    "    \"business_category_name\": \"Professional Services\",\n",
    "    \"overall_category_name\": null,\n",
    "    \"category_enum\": \"UNIVERSITY\",\n",
    "    \"category_name\": null,\n",
    "    \"profile_pic_url\": \"https://scontent-amt2-1.cdninstagram.com/v/t51.2885-19/s150x150/117066908_1128864954173821_2797787766361156925_n.jpg?_nc_ht=scontent-amt2-1.cdninstagram.com\\u0026_nc_ohc=PXsEzg-CKaUAX8dEtNL\\u0026tp=1\\u0026oh=86bb46d8006b77db2037955187e69de1\\u0026oe=6056619F\",\n",
    "    \"username\": \"uva_amsterdam\",\n",
    "    \"connected_fb_page\": null\n",
    "}\n",
    "```\n",
    "\n",
    "Can be loaded into Python as a dictionary:\n",
    "```python\n",
    "{\n",
    "    'biography': 'Welcome to the UvA ❌❌❌ \\nFind out more about our:\\n🏛 campuses 🎓 education 🔎 research\\nShare your 📸 using: #uva_amsterdam\\nQuestions? Contact us:',\n",
    "     'blocked_by_viewer': False,\n",
    "     'restricted_by_viewer': None,\n",
    "     'country_block': False,\n",
    "     'external_url': 'https://linkin.bio/uva_amsterdam',\n",
    "     'external_url_linkshimmed': 'https://l.instagram.com/?u=https%3A%2F%2Flinkin.bio%2Fuva_amsterdam&e=ATOBo7L11uPBpsMfd6-pFnoBRaF3T-6ovlD9Blc2q1LGUjnmyuGutPfuK-ib70Bt_YmGu6cDNCX1Y1lC&s=1',\n",
    "     'edge_followed_by': {'count': 42241},\n",
    "     'fbid': '17841401222133463',\n",
    "     'followed_by_viewer': False,\n",
    "     'edge_follow': {'count': 362},\n",
    "     'follows_viewer': False,\n",
    "     'full_name': 'UvA: University of Amsterdam',\n",
    "     'id': '1501672737',\n",
    "     'is_business_account': True,\n",
    "     'is_joined_recently': False,\n",
    "     'business_category_name': 'Professional Services',\n",
    "     'overall_category_name': None,\n",
    "     'category_enum': 'UNIVERSITY',\n",
    "     'category_name': None,\n",
    "     'profile_pic_url': 'https://scontent-amt2-1.cdninstagram.com/v/t51.2885-19/s150x150/117066908_1128864954173821_2797787766361156925_n.jpg?_nc_ht=scontent-amt2-1.cdninstagram.com&_nc_ohc=PXsEzg-CKaUAX8dEtNL&tp=1&oh=86bb46d8006b77db2037955187e69de1&oe=6056619F',\n",
    "     'username': 'uva_amsterdam',\n",
    "     'connected_fb_page': None\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main differences between dictionaries in Python and the JSON file notation are:\n",
    "\n",
    "* Python dictionaries exist in memory in Python, they are an abstract datatype. JSON is a data format and can be saved on your computer, or be transmitted as string (e.g. for a website request, sending data).\n",
    "* Keys in JSON can only be of type string. This means that writing a Python dictionary with integers as keys will transform them to string. Reading back the file will therefore give you a Python dictionary with strings as keys.\n",
    "* All non-ascii characters are escape sequences (e.g. `\\u274c`) for ❌. This is the same for letters with diacritics (e.g. é, ê, ç, ñ). If all characters are escaped this way, you don't have to specify an encoding when opening json files.\n",
    "* `True` and `False` are lowercased: `true` and `false`. `None` is `null`. \n",
    "* JSON only allows double quotes for its \"strings\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The built-in json module of Python needs to be imported first, to work with json files and notation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read a json file from our disk using `json.load()`. The file comes from the public API of the municipality of Amsterdam to look up information on houses by searching on street name and house number. See: https://api.data.amsterdam.nl/atlas/search/adres/. Most often, information from such API's or 'REST-services' is given back in JSON. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/bg1.json') as jsonfile:\n",
    "    data = json.load(jsonfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can inspect the loaded data as a Python dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(data))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we are only interested in the information on the building, we can take out that part to store it separately. This is the first dictionary element in the list that can be found under key `data['results']`. The rest of the information is feedback from the API, telling us that there is 1 hit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_selection = data['results'][0]\n",
    "\n",
    "# Delete all keys starting with an _underscore\n",
    "\n",
    "for k in list(data_selection):\n",
    "    if k.startswith('_'):\n",
    "        del data_selection[k]\n",
    "\n",
    "data_selection\n",
    "# print(type(data_selection))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, save it back to a json file using `json.dump()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stuff/bg1-selection.json', 'w') as outfile:\n",
    "    json.dump(data_selection, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Modify that function you previously built to generate statistics for a file once more so that it returns a python dictionary with these statistics.\n",
    "* Write a function that uses the `os.walk()` or `os.listdir()` method to run the file statistics function over every file in a folder. Create a dictionary that takes the file name as key, and the returned statistics dictionary as value.\n",
    "* Also add arguments for a `target_file_path`, and a `data` dictionary to that function. Use the `json.dump()` method to write the dictionary to the provided file path using a with statement.\n",
    "* Inspect the file by opening it on your computer with a text editor of some sorts. Find a way to make it 'pretty printed' (e.g. with _indents_). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "source_folder = \"data/gutenberg-extension\"\n",
    "target_file_path = \"stuff/gutenberg-statistics.json\"\n",
    "\n",
    "def your_modified_statistics_function(file_path):\n",
    "    # Your code\n",
    "    \n",
    "    return statistics_dict\n",
    "\n",
    "def your_functions_here():\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "def get_file_statistics(file_path, normalization=False):\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as infile:\n",
    "        text = infile.read()\n",
    "        \n",
    "    if normalization == True:\n",
    "        text = normalize(text)\n",
    "        \n",
    "    words = text.split()\n",
    "       \n",
    "    n_words = len(words)\n",
    "    n_unique = len(set(words))   \n",
    "    \n",
    "    counter = Counter(words)\n",
    "    most_common_words = counter.most_common(10)\n",
    "    \n",
    "    mfw = []\n",
    "    for word, freq in most_common_words:\n",
    "        mfw.append(word)\n",
    "    \n",
    "    statistics = dict()\n",
    "    \n",
    "    statistics['n_words'] = n_words\n",
    "    statistics['n_unique'] = n_unique\n",
    "    statistics['TTR'] = n_unique / n_words\n",
    "    statistics['MFW'] = [i[0] for i in most_common_words]\n",
    "        \n",
    "    return statistics\n",
    "\n",
    "def normalize(text):\n",
    "    \n",
    "    normalized_text = text.lower()\n",
    "    \n",
    "    for char in string.punctuation:\n",
    "        normalized_text = normalized_text.replace(char, '')\n",
    "    \n",
    "    return normalized_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statistics_for_folder(folder, target_file):\n",
    "    \"\"\"\"\"\"\n",
    "    \n",
    "    statistics_files = dict()\n",
    "    \n",
    "    for f in os.listdir(folder):\n",
    "        \n",
    "        filepath = os.path.join(folder, f)\n",
    "        \n",
    "        stats_dict = get_file_statistics(filepath)\n",
    "        \n",
    "        statistics_files[f] = stats_dict\n",
    "        \n",
    "    with open(target_file, 'w') as jsonfile:\n",
    "        json.dump(statistics_files, jsonfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_file_statistics('data/adams-hhgttg.txt')\n",
    "get_statistics_for_folder('data/gutenberg-extension/', 'stuff/gutenberg_statistics.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 (previously Exercise 6 in Notebook 2)\n",
    "\n",
    "Read the file `data/adams-hhgttg.txt` and:\n",
    "\n",
    "- Count the number of lines in the file\n",
    "\n",
    "- Count the number of non-empty lines\n",
    "\n",
    "- Read each line of the input file, remove its newline character and write it to file `stuff/adams-output.txt`\n",
    "\n",
    "- Compute the average number of alphanumeric characters per line\n",
    "\n",
    "- Identify all the unique words used in the text (no duplicates!) and write them in a text file called `stuff/lexicon.txt` (one word per line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "with open(\"stuff/lexicon.txt\", \"w\") as infile:\n",
    "    infile.write(\"something\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
