{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KV-UrkvK3HBQ"
   },
   "source": [
    "# Files: Graded assignment\n",
    "This notebook contains the third graded collaborative assignment of the 2023 Coding the Humanities course, and it is based on the [4. Reading And Writing Files](../../4_ReadingAndWritingFiles.ipynb) course material."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "13WY-Pd4m1Nq"
   },
   "source": [
    "This is a collaborative assignment. In the text cell below, please include all the names of your group members.\n",
    "\n",
    "Below that, answer the question using a mix of code cells and text cells in a way that would make your answers understandable to outsiders. To explain your code, you can use commenting (#) and/or text cells, similar to what you see in the course materials.\n",
    "\n",
    "If you used code or a solution from the internet (such as StackOverflow) or another external resource, please make reference to it (in any format). Unattributed copied code will be considered plagiarism and therefore fraud.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Authors of this answer:** Leonards Leimanis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IVxv8FjzoS_w",
    "tags": []
   },
   "source": [
    "# Assignment\n",
    "\n",
    "In the Data directory, you will find four snippets of texts by the philosopher Willard Quine, on various topics. We will do some file reading (and writing) to analyse these.\n",
    "\n",
    "Please use functions and function documentation where applicable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file *quine_elementarylogic_denial.txt* explains some basics of logic. Usually some empty space is left after logical formulae.\n",
    "\n",
    "1. From the file *quine_elementarylogic_denial.txt*, print only the lines that are not empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leona\\Documents\\Coding the humanities\\notebooks\\3_Files_GradedAssignment\\quine_elementarylogic_denial.txt\n"
     ]
    }
   ],
   "source": [
    "#Marking the directories on my PC\n",
    "local_path = \"C:\\\\Users\\\\leona\\\\Documents\\\\Coding the humanities\\\\notebooks\\\\3_Files_GradedAssignment\\\\\"\n",
    "def adding_local_d(path_to_data, filename):\n",
    "    if isinstance(path_to_data, str):\n",
    "        directroy = path_to_data + filename\n",
    "        return directroy\n",
    "\n",
    "print(adding_local_d(local_path, \"quine_elementarylogic_denial.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Denial\n",
      "Given any statement, we can form another by denying the first. The resulting denial is false or true according as the original statement is true or false. The denial of a statement will be written by putting the statement in question in the blank of '~(\t)''; but\n",
      "the parentheses will be suppressed unless the statement within them is a conjunction. Thus the denial of 'Kansas touches Iowa'' is:\n",
      "(1)\t~ Kansas touches Iowa, and the denial of §3(1) is:\n",
      "(2)\t~(Jones is ill. Smith is away).\n",
      "The tilde '~'' is a modified 'n'' and is conveniently read 'not''.\n",
      "The method of forming the denial in ordinary language is irregular. Sometimes 'not'' or 'does not'' or 'fails to'' is applied to the main verb; thus (1) might appear in words as 'Kansas does not touch Iowa'', or 'Kansas fails to touch Iowa''. If the statement has no one main verb, denial is accomplished by one or another periphrasis; e.g., the denial (2) might be rendered in words thus:\n",
      "(3)\tIt is not the case that Jones is ill and Smith is away.\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "with open(adding_local_d(local_path, \"data\\\\quine_elementarylogic_denial.txt\"), encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        if line.strip():  # check if line is not empty\n",
    "            print(line.strip())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. For the same file, calculate the percentage of lines that is not empty. To do this, you'll need the total number of lines and the number of non-empty lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of non-empty lines: 24.24%\n"
     ]
    }
   ],
   "source": [
    "with open(adding_local_d(local_path, \"data\\\\quine_elementarylogic_denial.txt\"), encoding='utf-8') as f:\n",
    "    total_lines = 0\n",
    "    non_empty_lines = 0\n",
    "    for line in f:\n",
    "        total_lines += 1\n",
    "        if line.strip():\n",
    "            non_empty_lines += 1\n",
    "    if total_lines > 0:\n",
    "        percentage = (non_empty_lines / total_lines) * 100\n",
    "    else:\n",
    "        percentage = 0\n",
    "\n",
    "    print(\"Percentage of non-empty lines: {:.2f}%\".format(percentage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the four text files contains paragraph markers in XML format, which enclose a paragraph. They look like this: `<p> </p>`. Find out which file it is (you do not need to use Python code for that). \n",
    "\n",
    "3. Create a version of the text without those markers. We would like it to be in the directory named 'out' to avoid overwriting the original file. You can do this by first reading the text file, using Python to remove the markers from the text, and then writing the text to a new file in the 'out' directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "8LSmnXOtm5sg"
   },
   "outputs": [],
   "source": [
    "# I need to import os because I am using windows not colab\n",
    "\n",
    "import os\n",
    "\n",
    "# Setting the input and output file paths\n",
    "input_path = adding_local_d(local_path, \"data\\\\quine_naturalknowledge_1975.txt\")\n",
    "output_dir = adding_local_d(local_path, \"out\")\n",
    "#Make sure the directory is created in case it is not\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "output_path = os.path.join(output_dir, \"Without_XML_Syntax.txt\")\n",
    "\n",
    "# Read the input file\n",
    "with open(input_path, \"r\") as input_file:\n",
    "    text = input_file.read()\n",
    "\n",
    "# Remove the <p> and </p> markers using string replace and also for capital letters\n",
    "text = text.replace(\"<p>\", \"\").replace(\"</p>\", \"\").replace(\"</P>\", \"\").replace(\"<P>\", \"\")\n",
    "\n",
    "# Write the modified text to the output file\n",
    "with open(output_path, \"w\") as output_file:\n",
    "    output_file.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Create a function that can compute the total number of words in all files in a directory, returning a single number. Apply it to the 'data' directory to get the number of words in all 4 files combined, and print the number. Use the NLTK tokenizer that was shown in this week's notebook for optimal results. For this question, don't worry too much about what exactly is a 'word', but if you can remove punctuation from the count somehow, that is nice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checked ✅ New Text Document.txt : 2\n",
      "Checked ✅ quine_elementarylogic_denial.txt : 179\n",
      "Checked ✅ quine_logic_syntax_1961.txt : 355\n",
      "Checked ✅ quine_naturalknowledge_1975.txt : 393\n",
      "Checked ✅ quine_paradox_1962.txt : 461\n",
      "Total number of words in all files: 1390\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import os\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "#nltk.download('punkt')\n",
    "#I think I have added most of the removable punctuation, but not sure becaus the texts are long\n",
    "removable_characters = [',', '(', ')', '.', '?', '!', ':', '~', '`', ';', '\"', \"'\", '»', \"<p>\", \"</p>\", \"<P>\", \"</P>\"]\n",
    "def character_removal(string):\n",
    "    for char in removable_characters:\n",
    "        string = string.replace(char, '')\n",
    "    return string\n",
    "\n",
    "def count_words_in_directory(directory):\n",
    "    word_count = 0\n",
    "    for filename in os.listdir(directory):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        \n",
    "        if os.path.isfile(filepath):\n",
    "            with open(filepath, \"r\") as file:\n",
    "                text = file.read()\n",
    "                text = character_removal(text)\n",
    "                words = word_tokenize(text)\n",
    "                word_count += len(words)\n",
    "                print(f\"Checked ✅ {filename} : {len(words)}\") #for checking\n",
    "    return word_count\n",
    "\n",
    "# Call the function on the 'data' directory and print the result\n",
    "data_dir = adding_local_d(local_path, \"data\\\\\")\n",
    "total_word_count = count_words_in_directory(data_dir)\n",
    "print(\"Total number of words in all files: {}\".format(total_word_count))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2-Weekly-Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
