{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "_ff2UYOrk_bd"
   },
   "source": [
    "# Individual Exam CtH | Analysing \"Brand Twitter\"\n",
    "\n",
    "### Author: *Name* Leonards Leimanis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rlBTVZLP_9cX"
   },
   "source": [
    "Be sure to check the assignment description on Canvas once more.\n",
    "\n",
    "Handing in the notebook should be done in a `zip` file, together with any files you create. We request you to name the exam submission as \"exam_name_studentname.zip\" with your corresponding name. The data is presented in the `data` folder. Also, include the files containing the data when handing in your exam, as this helps us to check your code when re-running it. To check if we can run your notebook from top to bottom without receiving errors, try to clear all the output of the cells and rerun everything. This can be done automatically by clicking on `Runtime --> Restart and run all`.\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U0z7yBxIPWJc"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "For this assignment we will investigate the phenomenon of \"*Brand Twitter*\". While corporate communication is traditionally rather bland, in recent years a trend has emerged of brands communicating on social media in a far less formal way. Social media teams of certain brands have started use memes, edgy humour and an informal and personal style of writing, sometimes also engaging with other brand accounts in a way that is similar to how many Twitter users tweet and interact with each other. This phenomenon of corporate personhood has been called *Brand Twitter*.\n",
    "\n",
    "In 2019, Vulture published a history of the phenomenon, just in case you find it interesting: https://www.vulture.com/2019/06/brand-twitter-jokes-history.html\n",
    "\n",
    "For this assignment we will consider a group of brand accounts that are often considered part of *Brand Twitter*:\n",
    "\n",
    "    * @Wendys - Wendy's\n",
    "    * @PrimeVideo - Amazon Prime Video\n",
    "    * @MerriamWebster - Merriam Webster\n",
    "    * @BurgerKing - Burger King\n",
    "    * @Netflix - Netflix US\n",
    "    * @McDonalds - McDonald's\n",
    "    * @DennysDiner - Denny's Diner\n",
    "\n",
    "We thought it would be interesting to analyse the tweets of these brand accounts to learn more about this novel style of corporate communication and the ways corporations might be perceived as relatable people on social media."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nI8_S13FGYWN"
   },
   "source": [
    "# Data\n",
    "\n",
    "The data can be found within the file `brand_tweets.csv`. This file contains twitter data on tweets (every row is one tweet) by these brands.\n",
    "\n",
    "FYI: This data was acquired from Twitter using their API if you're interested, following the method from the optional Notebook 7.\n",
    "\n",
    "*Please note: this dataset might contain content which could be considered as offensive. It is real unfiltered data directly from Twitter.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9vwI8QmUKJYk"
   },
   "source": [
    "# Tasks\n",
    "\n",
    "We would like to look through some recent tweets of *Brand Twitter*, and be able to understand certain characteristics of their tweets. As these Twitter accounts represent major brands, one particularly interesting aspect of this dataset is the difference between regular tweets and tweets that are replies to other tweets, which could be replies to customers or other brands.\n",
    "\n",
    "Make your code and results as pretty as possible, and feel free to use tabs and enumeration when printing text and formatting for the visualisations. \n",
    "\n",
    "This assignment is about getting familiar with Pandas' methods â€” we suggest going through the lecture and seminar notebooks on Pandas again. You can of course use any course material in this assignment!\n",
    "\n",
    "You are not limited to the structure of the cells below with ` # Your code here` only. Organise your code the way you think is most readible and appropriate.\n",
    "\n",
    "If you do not fully manage to solve a question in the requested way, feel free to solve it in a different way to be able to proceed with later questions - you'll probably still get some points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pS58nZzcKA44"
   },
   "source": [
    "### Question 1: Pre-processing\n",
    "* Add a column with a normalised version of the 'text' column. Use an appropriate tokenizer for this type of data in your normalization function. As the 'text' column contains strings, things will be easier if your normalized text column will also contain strings.\n",
    "\n",
    "Continue to work with this normalized column in the next tasks. You're of course free to add more columns if you think you need them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "csv_file = \"C:\\\\Users\\\\leona\\\\Documents\\\\Coding the humanities\\\\notebooks\\\\CtH-final\\\\data\\\\brand_tweets.csv\"\n",
    "\n",
    "df_tweets = pd.read_csv(csv_file, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "DVwFEgSAPN5P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@OGPettyMe Hi, we are sorry to hear this was your experience. Can you please DM us your full name, phone number, email linked to the app, as well as the complete address of the store location, so we can check this out? Thanks! https://t.co/x3nIBXfzQA\n",
      "['@ogpettyme', 'hi', 'we', 'are', 'sorry', 'to', 'hear', 'this', 'was', 'your', 'experience', 'can', 'you', 'please', 'dm', 'us', 'your', 'full', 'name', 'phone', 'number', 'email', 'linked', 'to', 'the', 'app', 'as', 'well', 'as', 'the', 'complete', 'address', 'of', 'the', 'store', 'location', 'so', 'we', 'can', 'check', 'this', 'out', 'thanks']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "import re\n",
    "\n",
    "tokenizer = TweetTokenizer(preserve_case=True, reduce_len=False, strip_handles=False)\n",
    "\n",
    "#using my character removal function I made in a previous assignment\n",
    "removable_characters = [',', '(', ')', '.', '?', '!', ':', '~', '`', ';', '\"', 'Â»', \"<p>\", \"</p>\", \"<P>\", \"</P>\", \"â‚¬\"]\n",
    "def character_removal(string):\n",
    "    clean_string = string\n",
    "    for char in removable_characters:\n",
    "        clean_string = clean_string.replace(char, '')\n",
    "    return clean_string\n",
    "\n",
    "#making the tweet tokenizer function, but I am going to keep it a list since then I can count words easy\n",
    "#added the link removal method from here afterwards https://stackoverflow.com/questions/11331982/how-to-remove-any-url-within-a-string-in-python\n",
    "def tweet_normalizer(text):\n",
    "    words = tokenizer.tokenize(re.sub(r'http\\S+', '', text.lower().replace('â€™', \"'\")))\n",
    "    return  words\n",
    "    \n",
    "df_tweets['normalized_text'] = df_tweets['text'].apply(character_removal).apply(tweet_normalizer)\n",
    "\n",
    "#demonstration of working    \n",
    "print(df_tweets['text'][10282])\n",
    "print(df_tweets['normalized_text'][10282])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "c05kDUHdOCkV"
   },
   "source": [
    "### Question 2: Description / statistics\n",
    "\n",
    "Provide information on: \n",
    "\n",
    "1. Number of tweets (per brand and in total)\n",
    "2. How many of those tweets are replies (per brand and in total)\n",
    "3. Most liked tweet (per brand and in total)\n",
    "4. Most frequent hashtags (per brand and in total)\n",
    "\n",
    "You can present the answers in this notebook. If you prefer, you may also write your results to a separate text file (optional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "_xdsHrGqOBP5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Count of Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total</td>\n",
       "      <td>19915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BurgerKing</td>\n",
       "      <td>3248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>McDonalds</td>\n",
       "      <td>3248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wendys</td>\n",
       "      <td>3246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DennysDiner</td>\n",
       "      <td>3210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MerriamWebster</td>\n",
       "      <td>3169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PrimeVideo</td>\n",
       "      <td>1966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Netflix</td>\n",
       "      <td>1828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Brand  Count of Tweets\n",
       "0           Total            19915\n",
       "1      BurgerKing             3248\n",
       "2       McDonalds             3248\n",
       "3          Wendys             3246\n",
       "4     DennysDiner             3210\n",
       "5  MerriamWebster             3169\n",
       "6      PrimeVideo             1966\n",
       "7         Netflix             1828"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweets_per_brand = df_tweets['username'].value_counts()\n",
    "tweets_total = df_tweets['username'].count()\n",
    "\n",
    "df_tweets_count = pd.DataFrame({'Brand': tweets_per_brand.index, 'Count of Tweets': tweets_per_brand.values})\n",
    "\n",
    "#making a pretty print\n",
    "df_tweets_count.loc[-1] = ['Total', tweets_total]  \n",
    "df_tweets_count.index = df_tweets_count.index + 1  \n",
    "df_tweets_count = df_tweets_count.sort_index()\n",
    "\n",
    "display(df_tweets_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Brand  Count of reply Tweets\n",
      "0           Total                  12975\n",
      "1       McDonalds                   3245\n",
      "2      BurgerKing                   3183\n",
      "3          Wendys                   3170\n",
      "4     DennysDiner                   2182\n",
      "5  MerriamWebster                    789\n",
      "6         Netflix                    297\n",
      "7      PrimeVideo                    109\n"
     ]
    }
   ],
   "source": [
    "#counting tweets\n",
    "reply_tweets_per_brand = df_tweets[df_tweets['text'].str.contains('^@')]['username'].value_counts()\n",
    "total_reply_tweets = len(df_tweets[df_tweets['text'].str.contains('^@')])\n",
    "\n",
    "#print\n",
    "df_reply_count = pd.DataFrame({'Brand': reply_tweets_per_brand.index, 'Count of reply Tweets': reply_tweets_per_brand.values})\n",
    "\n",
    "df_reply_count.loc[-1] = ['Total', total_reply_tweets]\n",
    "df_reply_count.index = df_reply_count.index + 1\n",
    "df_reply_count = df_reply_count.sort_index()\n",
    "\n",
    "print(df_reply_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most liked tweets per brand:\n",
      "                                                             text  like_count\n",
      "username                                                                     \n",
      "BurgerKing      bk boss: did you write those tweets i asked fo...        2340\n",
      "DennysDiner     find cute baby from viral video and bring him ...       75985\n",
      "McDonalds       i read all the comments ðŸ«¶ https://t.co/6mLhl44v1L       13235\n",
      "MerriamWebster  ONE OF THE DEFINITIONS OF 'LITERALLY' IS \"IN E...       46434\n",
      "Netflix         Wednesday has been officially renewed for Seas...      285514\n",
      "PrimeVideo      Like if you can hear this image. https://t.co/...      121871\n",
      "Wendys                     .@elonmusk let me tweet from space pls       73937\n",
      "\n",
      "\n",
      "Most liked tweet overall from Netflix:\n",
      "                                                                       text like_count\n",
      "Wednesday has been officially renewed for Season 2! https://t.co/ekqlxP9ueW     285514\n"
     ]
    }
   ],
   "source": [
    "#sorting all tweets by number of likes\n",
    "sorted_by_likes = df_tweets.sort_values(by='like_count', ascending=False)\n",
    "\n",
    "#each usernames top tweet\n",
    "most_liked_per_brand = sorted_by_likes.groupby('username').first()[['text', 'like_count']]\n",
    "\n",
    "#top tweet overall\n",
    "most_liked_tweet = sorted_by_likes.iloc[0][['text', 'like_count']]\n",
    "\n",
    "#print\n",
    "print(\"Most liked tweets per brand:\")\n",
    "print(most_liked_per_brand)\n",
    "\n",
    "print()\n",
    "\n",
    "print(f\"\\nMost liked tweet overall from {sorted_by_likes.iloc[0]['username']}:\")\n",
    "print(most_liked_tweet.to_frame().T.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall most frequent hashtags:\n",
      "            Hashtag  Count\n",
      "      #WordOfTheDay    714\n",
      "             #TUDUM     74\n",
      "       #MyPoliceman     68\n",
      "   #TheRingsOfPower     58\n",
      "        #TNFonPrime     53\n",
      "#WendysHotandCrispy     43\n",
      "     #ThePeripheral     40\n",
      "         #SAGAwards     37\n",
      "     #HarlemOnPrime     33\n",
      "       #SpellingBee     28\n",
      "\n",
      "Most frequent hashtags for Wendys:\n",
      "            Hashtag  Count\n",
      "#WendysHotandCrispy     43\n",
      "#ChooseHotAndCrispy     22\n",
      "#WendysHotAndCrispy      6\n",
      "#ChooseHotandCrispy      4\n",
      "        #Daytona500      1\n",
      "       #PandoraLIVE      1\n",
      "      #ifhewantedto      1\n",
      "     #knowyourworth      1\n",
      "     #TwitchCon2022      1\n",
      "             #USMNT      1\n",
      "\n",
      "Most frequent hashtags for PrimeVideo:\n",
      "                     Hashtag  Count\n",
      "                #MyPoliceman     68\n",
      "            #TheRingsOfPower     58\n",
      "                 #TNFonPrime     53\n",
      "              #ThePeripheral     40\n",
      "              #HarlemOnPrime     33\n",
      "        #DaisyJonesAndTheSix     23\n",
      "                 #GoodRivals     13\n",
      "#ThePeopleWeHateAtTheWedding     13\n",
      "      #SomethingFromTiffanys     12\n",
      "                   #JackRyan     12\n",
      "\n",
      "Most frequent hashtags for MerriamWebster:\n",
      "                 Hashtag  Count\n",
      "           #WordOfTheDay    714\n",
      "            #SpellingBee     28\n",
      "              #etymology     10\n",
      "            #PopRhetoric      9\n",
      "           #WordWellUsed      7\n",
      "                 #Oscars      3\n",
      "   #NationalThesaurusDay      2\n",
      "#IndependentBookstoreDay      2\n",
      "                      #1      2\n",
      "                      #2      2\n",
      "\n",
      "Most frequent hashtags for BurgerKing:\n",
      "             Hashtag  Count\n",
      "      #BurgerKingYes     19\n",
      "            #yourule      8\n",
      "            #YouRule      5\n",
      "          #BKContest      5\n",
      "         #BKWarmCore      3\n",
      "    #HomeOfTheGhosts      3\n",
      "#NationalKindnessDay      1\n",
      "      #friesoverguys      1\n",
      "     #WhopperWhopper      1\n",
      "         #capricorns      1\n",
      "\n",
      "Most frequent hashtags for Netflix:\n",
      "             Hashtag  Count\n",
      "              #TUDUM     74\n",
      "          #SAGAwards     37\n",
      "#NetflixSaveTheDates     19\n",
      "      #ChrisRockLive      7\n",
      "        #EverybodyIn      7\n",
      "        #EVsOnScreen      7\n",
      "             #Oscars      5\n",
      "  #StrangerThingsDay      5\n",
      "              #Emmys      5\n",
      "   #WednesdayThought      2\n",
      "\n",
      "Most frequent hashtags for McDonalds:\n",
      "Hashtag  Count\n",
      "     #1      4\n",
      "\n",
      "Most frequent hashtags for DennysDiner:\n",
      "                Hashtag  Count\n",
      "              #DennysFC     21\n",
      "       #DennysBreakFast     20\n",
      "        #HappyDaddysDay     17\n",
      "             #NFTforNKH      6\n",
      "             #TheMatrix      6\n",
      "       #AllPancakerTeam      5\n",
      "       #DennysSauceWars      5\n",
      "#INTERNATIONALCOFFEEDAY      5\n",
      "      #EndlessBreakfast      5\n",
      "                     #2      4\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_hashtags(text):\n",
    "    hashtags = re.findall(r'\\#\\w+', text)\n",
    "    return hashtags\n",
    "\n",
    "df_tweets['hashtags'] = df_tweets['text'].apply(extract_hashtags)\n",
    "\n",
    "all_hashtags = []\n",
    "for hashtags in df_tweets['hashtags']:\n",
    "    all_hashtags.extend(hashtags)\n",
    "\n",
    "hashtags_count = pd.Series(all_hashtags).value_counts()\n",
    "\n",
    "#using print formating from previous tasks\n",
    "print(\"Overall most frequent hashtags:\")\n",
    "df_hashtags_count = pd.DataFrame({'Hashtag': hashtags_count.index, 'Count': hashtags_count.values})\n",
    "df_hashtags_count.index += 1\n",
    "df_hashtags_count.index.name = 'Rank'\n",
    "print(df_hashtags_count.head(10).to_string(index=False))\n",
    "\n",
    "for brand in df_tweets['username'].unique():\n",
    "    brand_hashtags = []\n",
    "    for text in df_tweets[df_tweets['username'] == brand]['text']:\n",
    "        hashtags = extract_hashtags(text)\n",
    "        brand_hashtags.extend(hashtags)\n",
    "    brand_hashtags_count = pd.Series(brand_hashtags).value_counts()\n",
    "    print(f\"\\nMost frequent hashtags for {brand}:\")\n",
    "   \n",
    "    df_brand_hashtags_count = pd.DataFrame({'Hashtag': brand_hashtags_count.index, 'Count': brand_hashtags_count.values})\n",
    "    df_brand_hashtags_count.index += 1\n",
    "    df_brand_hashtags_count.index.name = 'Rank'\n",
    "    \n",
    "    print(df_brand_hashtags_count.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Question 3: Analysis - Corporate personhood\n",
    "\n",
    "To observe to what extent the brands encourage corporate personhood, it would be interesting to see what pronouns the brands use to refer to themselves: \"we\" or \"I\". Let us define a \"First Person Pronoun Ratio\" - the total number of times that the word \"I\" is used by a brand / the total number of times the words \"I\" or \"we\" are used by a brand. This should give us a value between 0 and 1, and a higher value indicates that the brand used the word \"I\" relatively more often compared to the word \"we\". If we multiply this value by 100, it becomes a percentage.\n",
    "\n",
    "1. For all of the 7 brands, compute their First Person Pronoun Ratio (or percentage) as defined here.\n",
    "2. Choose the brand with the highest First Person Pronoun Ratio. For this brand, compute the First Person Pronoun Ratio separately for tweets that are replies and tweets that are not replies.\n",
    "\n",
    "Briefly interpret the result (as a text block)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First person pronoun ratio (in %) per brand:\n",
      "Wendys: 19.22%\n",
      "PrimeVideo: 36.11%\n",
      "MerriamWebster: 12.87%\n",
      "BurgerKing: 0.42%\n",
      "Netflix: 70.00%\n",
      "McDonalds: 2.46%\n",
      "DennysDiner: 16.62%\n"
     ]
    }
   ],
   "source": [
    "def compute_fpp_ratio(df, brand):\n",
    "    df_brand = df[df['username'] == brand]\n",
    "    #count the occurances of i and we and we're\n",
    "    i_count = 0\n",
    "    we_count = 0\n",
    "\n",
    "    #using different variations for the I uses\n",
    "    for text in df_brand['normalized_text']:\n",
    "        i_count += text.count('i')\n",
    "        i_count += text.count(\"i'll\")\n",
    "        i_count += text.count(\"i'm\")\n",
    "        i_count += text.count(\"im\")\n",
    "        we_count += text.count('we')\n",
    "        we_count += text.count(\"we're\")\n",
    "        we_count += text.count(\"we'll\")\n",
    "    \n",
    "    #i_count / (i_count + we_count)\n",
    "    if i_count + we_count == 0:\n",
    "        fpp_ratio = 0\n",
    "    else:\n",
    "        fpp_ratio = i_count / (i_count + we_count)\n",
    "    \n",
    "    return fpp_ratio\n",
    "\n",
    "#computing fpp ratio for each brand\n",
    "fpp_ratios = {}\n",
    "for brand in df_tweets['username'].unique():\n",
    "    fpp_ratio = compute_fpp_ratio(df_tweets, brand)\n",
    "    fpp_ratios[brand] = fpp_ratio\n",
    "\n",
    "#printing\n",
    "print(\"First person pronoun ratio (in %) per brand:\")\n",
    "for brand, fpp_ratio in fpp_ratios.items():\n",
    "    print(f\"{brand}: {fpp_ratio * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brand with highest FPP Ratio: Netflix\n",
      "FPP Ratio for non-reply tweets: 0.67\n",
      "FPP Ratio for reply tweets: 0.76\n"
     ]
    }
   ],
   "source": [
    "#getting the highest fpp ratio\n",
    "brand_with_highest_fpp_ratio = max(fpp_ratios, key=fpp_ratios.get)\n",
    "\n",
    "def fpp_ratio_replyandnon(brand_to_examine):\n",
    "    df_brand = df_tweets[df_tweets['username'] == brand_to_examine]\n",
    "    #count the number of times I and we are used in the normalized text for non-reply tweets\n",
    "    i_count_nonreply = 0\n",
    "    we_count_nonreply = 0\n",
    "    for text in df_brand[df_brand['text'].str.contains('@', regex=True) == False]['normalized_text']:\n",
    "        i_count_nonreply += text.count('i')\n",
    "        i_count_nonreply += text.count(\"i'll\")\n",
    "        i_count_nonreply += text.count(\"i'm\")\n",
    "        i_count_nonreply += text.count(\"im\")\n",
    "        we_count_nonreply += text.count('we')\n",
    "        we_count_nonreply += text.count(\"we're\")\n",
    "        we_count_nonreply += text.count(\"we'll\")\n",
    "\n",
    "    #compute fpp for non reply tweets\n",
    "    if i_count_nonreply + we_count_nonreply == 0:\n",
    "        fpp_ratio_nonreply = 0\n",
    "    else:\n",
    "        fpp_ratio_nonreply = i_count_nonreply / (i_count_nonreply + we_count_nonreply)\n",
    "\n",
    "    #count the number of times I and we are used in the normalized text for reply tweets\n",
    "    i_count_reply = 0\n",
    "    we_count_reply = 0\n",
    "    for text in df_brand[df_brand['text'].str.contains('@', regex=True) == True]['normalized_text']:\n",
    "        i_count_reply += text.count('i')\n",
    "        i_count_reply += text.count(\"i'll\")\n",
    "        i_count_reply += text.count(\"i'm\")\n",
    "        i_count_reply += text.count(\"im\")\n",
    "        we_count_reply += text.count(\"we\")\n",
    "        we_count_reply += text.count(\"we're\")\n",
    "        we_count_reply += text.count(\"we'll\")\n",
    "\n",
    "    #compute fpp for reply tweets\n",
    "    if i_count_reply + we_count_reply == 0:\n",
    "        fpp_ratio_reply = 0\n",
    "    else:\n",
    "        fpp_ratio_reply = i_count_reply / (i_count_reply + we_count_reply)\n",
    "\n",
    "    #print\n",
    "    print(f\"Brand with highest FPP Ratio: {brand_to_examine}\")\n",
    "    print(f\"FPP Ratio for non-reply tweets: {fpp_ratio_nonreply:.2f}\")\n",
    "    print(f\"FPP Ratio for reply tweets: {fpp_ratio_reply:.2f}\")\n",
    "\n",
    "fpp_ratio_replyandnon(brand_with_highest_fpp_ratio)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "McDonalds uses the pronouns we pronoun mostly which means that their twitter account sees them as a team of multiple people working for McDonalds.\n",
    "Netlfix has the highest use of I an we in their tweets. More than half of their tweets contain I which means that the Netlfix account is set up to treat itself as a single person. Possibly using we for situations where the company has to take responsibility. The use of I in reply and non reply tweets stays about equaly high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yy4BDoPAOcp9"
   },
   "source": [
    "### Question 4: Analysis - Brand interaction\n",
    "\n",
    "Among the tweets that are replies, do the *Brand Twitter* brands reply to each other? (in a tweet this is done by writing @username at the beginning of the tweet)\n",
    "\n",
    "1. Print three tweets from the dataframe in which a brand mentions one of the other brands.\n",
    "2. For all of the 7 brands, find out how often they mention each of the other brands in replies. Present the result as a DataFrame.\n",
    " \n",
    "Briefly interpret the result (as a text block)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "7fraxfplOo4i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mentioned by Wendys - @Visible @Wendys\n",
      "mentioned by BurgerKing - @ZarZanganeh @Wendys Hi Zar!ðŸ‘‹ Thank you for letting us know. Can you send us a DM so we can further assist? ðŸ‘‘\n",
      "mentioned by MerriamWebster - @PrimeVideo ðŸ‘€\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "#filtering a dataframe with reply tweets\n",
    "df_replies = df_tweets[df_tweets['text'].str.startswith('@')]\n",
    "count = 0\n",
    "\n",
    "for brand in df_replies['username'].unique():\n",
    "    brand_tweets = df_replies[df_replies['text'].str.contains(fr'@{brand}\\b')]\n",
    "\n",
    "    for tweet in brand_tweets[['text', 'username']].itertuples(index=False):\n",
    "        print(f'mentioned by {tweet[1]} - {tweet[0]}')\n",
    "        count += 1\n",
    "        if count == 3:\n",
    "            break\n",
    "    if count == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wendys</th>\n",
       "      <th>PrimeVideo</th>\n",
       "      <th>MerriamWebster</th>\n",
       "      <th>BurgerKing</th>\n",
       "      <th>Netflix</th>\n",
       "      <th>McDonalds</th>\n",
       "      <th>DennysDiner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PrimeVideo</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MerriamWebster</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BurgerKing</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netflix</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>McDonalds</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DennysDiner</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wendys</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Wendys  PrimeVideo  MerriamWebster  BurgerKing  Netflix  \\\n",
       "PrimeVideo         0.0         NaN             1.0         0.0      0.0   \n",
       "MerriamWebster     0.0         0.0             NaN         0.0      0.0   \n",
       "BurgerKing         9.0         0.0             0.0         NaN      0.0   \n",
       "Netflix            0.0         0.0             0.0         0.0      NaN   \n",
       "McDonalds         19.0         0.0             0.0         1.0      0.0   \n",
       "DennysDiner        1.0         0.0             0.0         0.0      0.0   \n",
       "Wendys             NaN         0.0             0.0         1.0      0.0   \n",
       "\n",
       "                McDonalds  DennysDiner  \n",
       "PrimeVideo            0.0          0.0  \n",
       "MerriamWebster        0.0          1.0  \n",
       "BurgerKing            0.0          1.0  \n",
       "Netflix               0.0          0.0  \n",
       "McDonalds             NaN          0.0  \n",
       "DennysDiner           0.0          NaN  \n",
       "Wendys                0.0          0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def brand_interactions(dataframe, username):\n",
    "    df_replies = dataframe[dataframe['text'].str.startswith('@')]\n",
    "    \n",
    "    brand_mentions = {}\n",
    "    for brand in dataframe[username].unique():\n",
    "        brand_mentions[brand] = {}\n",
    "        for other_brand in dataframe[username].unique():\n",
    "            #inlcuded this so the it does not collect data about self mentions\n",
    "            if brand != other_brand:\n",
    "                brand_mentions[brand][other_brand] = 0\n",
    "\n",
    "    for brand in dataframe[username].unique():\n",
    "        brand_tweets = df_replies[df_replies[username] == brand]\n",
    "        for other_brand in dataframe[username].unique():\n",
    "            if brand != other_brand:\n",
    "                mentions = brand_tweets['text'].str.count(fr'@{other_brand}\\b', re.IGNORECASE).sum()\n",
    "                brand_mentions[brand][other_brand] = mentions\n",
    "\n",
    "    #converting dictionary for pandas df\n",
    "    df_brand_mentions = pd.DataFrame(brand_mentions)\n",
    "    display(df_brand_mentions)\n",
    "\n",
    "brand_interactions(df_tweets, 'username')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wRYM_Nr2Osxw"
   },
   "source": [
    "### Question 5: Visualization\n",
    "\n",
    "1. Plot the number of tweets in the whole dataset per week. \n",
    "    * Interpret the graph. Can you explain the overall pattern and/or some of the fluctuations that are visible? Feel free to also make reference to the numbers you computed for Question 2 in your explanation.\n",
    "    * (If needed, restrict the dataframe to an active twitter timeframe)\n",
    "\n",
    "2. Choose one of the seven brands and plot its (Twitter) popularity over time (choose the time unit and range of your choice) by:\n",
    "    * Number of retweets\n",
    "    * Number of likes\n",
    "  \n",
    "  You can either try to plot these two metrics (retweets/likes) in the same figure, or create multiple figures.\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "wdQOJkcVOb7b"
   },
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Exam_CtH_2022.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
